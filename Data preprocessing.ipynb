{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import combinations\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import early_stopping\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna  # pip install optuna\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train data set\n",
    "# https://www.kaggle.com/datasets/raddar/amex-data-integer-dtypes-parquet-format\n",
    "train = pd.read_parquet('C:\\\\Users\\\\16122\\\\AMEX Kaggle Competition\\\\train.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list that includes all features except 'customer_ID' and 'S_2'\n",
    "all_cols = [col for col in list(train.columns) if col not in ['customer_ID','S_2']]\n",
    "\n",
    "# define a list of catagorical features that were provided by AMEX\n",
    "cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "\n",
    "# define a list of numerical features\n",
    "num_features = [col for col in all_cols if col not in cat_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change feature 'S_2' to datetime\n",
    "train['S_2'] = pd.to_datetime(train['S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that returns a list of numerical features with more than (threshold*100)% of null values\n",
    "def find_null_num(df, threshold):\n",
    "    nullvals = df[num_features].isnull().sum() / df.shape[0]\n",
    "    etnullCols = nullvals[nullvals>threshold].index.to_list()\n",
    "    return etnullCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D_73', 'B_29', 'D_88', 'D_110', 'B_39', 'B_42', 'D_132', 'D_134']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'etnullCols' contains numerical features with more than 90% null values \n",
    "etnullCols = find_null_num(train, 0.9)\n",
    "etnullCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features that are differences between last and lag1 \n",
    "# kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "\n",
    "def get_difference(data, num_features):\n",
    "    df1 = []\n",
    "    customer_ids = []\n",
    "    for customer_id, df in tqdm(data.groupby(['customer_ID'])):\n",
    "        # Get the differences\n",
    "        diff_df1 = df[num_features].diff(1).iloc[[-1]].values.astype(np.float32)\n",
    "        # Append to lists\n",
    "        df1.append(diff_df1)\n",
    "        customer_ids.append(customer_id)\n",
    "    # Concatenate\n",
    "    df1 = np.concatenate(df1, axis = 0)\n",
    "    # Transform to dataframe\n",
    "    df1 = pd.DataFrame(df1, columns = [col + '_diff1' for col in df[num_features].columns])\n",
    "    # Add customer id\n",
    "    df1['customer_ID'] = customer_ids\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 458913/458913 [06:18<00:00, 1213.92it/s]\n"
     ]
    }
   ],
   "source": [
    "train_diff = get_difference(train, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define different types of categorical features. We are going to handle them differently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features that have low cardinality\n",
    "# https://www.kaggle.com/code/illidan7/amex-basic-feature-engineering-1500-features\n",
    "\n",
    "# cat2 features (Low cardinality features; <=4 unique values)\n",
    "cat2_features = ['B_31','B_32','B_33','D_103','D_109','D_111','D_127',\n",
    "                'D_129','D_135','D_137','D_139','D_140','D_143','D_86',\n",
    "                'D_87','D_92','D_93','D_94','D_96','R_15','R_19','R_2','R_21',\n",
    "                'R_22','R_23','R_24','R_25','R_28','R_4','S_18','S_20','S_6']\n",
    "\n",
    "# cat3 features (Low cardinality features; >=8 and <=21 unique values)\n",
    "cat3_features = ['R_9','R_18','R_10','R_11','D_89','D_91','D_81','D_82','D_136',\n",
    "                'D_138','D_51','D_123','D_125','D_108','B_41','B_22',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that there is no overlap between etnullCols (columms with more than 90% null values)\n",
    "# and cat2_features+cat3_features (low cardinality features)\n",
    "over_lap = []\n",
    "for col in etnullCols:\n",
    "    if col in cat2_features or col in cat3_features:\n",
    "        over_lap.append(col)\n",
    "over_lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a list of numerical features that exclude low cardinality features\n",
    "non_num = etnullCols + cat2_features + cat3_features\n",
    "num_fea = [col for col in num_features if col not in non_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_feature_engineer(df):\n",
    "    # FEATURE ENGINEERING FROM \n",
    "    # https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n",
    "    \n",
    "    #create 'mean', 'std', 'min', 'max', 'last' columns for numerical features\n",
    "    train_num_agg = df.groupby(\"customer_ID\")[num_fea].agg(['mean', 'std', 'min', 'max', 'last'])\n",
    "    train_num_agg.columns = ['_'.join(x) for x in train_num_agg.columns]\n",
    "    train_num_agg.reset_index(inplace = True)\n",
    "    \n",
    "    #create 'count', 'last', 'nunique' for categorical features\n",
    "    train_cat_agg = df.groupby(\"customer_ID\")[cat_features].agg(['count', 'last', 'nunique'])\n",
    "    train_cat_agg.columns = ['_'.join(x) for x in train_cat_agg.columns]\n",
    "    train_cat_agg.reset_index(inplace = True)\n",
    "    \n",
    "    #create only 'last' for exnullCols\n",
    "    train_etnull_agg = df.groupby(\"customer_ID\")[etnullCols].agg(['last'])\n",
    "    train_etnull_agg.columns = ['_'.join(x) for x in train_etnull_agg.columns]\n",
    "    \n",
    "    #create 'last' and 'unique' for cat2_features\n",
    "    train_cat2_agg = df.groupby(\"customer_ID\")[cat2_features].agg(['last', 'nunique'])\n",
    "    train_cat2_agg.columns = ['_'.join(x) for x in train_cat2_agg.columns]\n",
    "    \n",
    "    #cat3_features are treated like num_fea but with one more 'nunique' column\n",
    "    train_cat3_agg = df.groupby(\"customer_ID\")[cat3_features].agg(['last', 'nunique','min', 'max','mean', 'std'])\n",
    "    train_cat3_agg.columns = ['_'.join(x) for x in train_cat3_agg.columns]\n",
    "    \n",
    "    #merge all together\n",
    "    df = train_num_agg.merge(train_cat_agg, how = 'inner', on = 'customer_ID').merge(train_etnull_agg, how = 'inner', on = 'customer_ID').merge(train_cat2_agg, how = 'inner', on = 'customer_ID').merge(train_cat3_agg, how = 'inner', on = 'customer_ID')\n",
    "    del train_num_agg, train_cat_agg, train_etnull_agg, train_cat2_agg, train_cat3_agg\n",
    "    print('shape after engineering', df.shape )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after engineering (458913, 807)\n"
     ]
    }
   ],
   "source": [
    "train = process_and_feature_engineer(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_mean_col = cat3_features + num_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features that are differences between last and mean \n",
    "# kaggle.com/code/ragnar123/amex-lgbm-dart-cv-0-7977\n",
    "def last_mean_diff(df,num_cols):\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            df[f'{col}_last_mean_diff'] = df[f'{col}_last'] - df[f'{col}_mean']\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_mean_diff(train, last_mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features that are (max-last)/(max-min)\n",
    "def last_max_ratio(df, num_cols):\n",
    "    for col in num_cols:\n",
    "        try:\n",
    "            df[f'{col}_last_max_ratio'] = (df[f'{col}_max']-df[f'{col}_last'])/(df[f'{col}_max']-df[f'{col}_min'])\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_max_ratio(train, last_mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some columns that contain inf values \n",
    "train.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(train_diff, how = 'left', on = 'customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>P_2_min</th>\n",
       "      <th>P_2_max</th>\n",
       "      <th>P_2_last</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>D_39_min</th>\n",
       "      <th>D_39_max</th>\n",
       "      <th>...</th>\n",
       "      <th>D_136_diff1</th>\n",
       "      <th>D_137_diff1</th>\n",
       "      <th>D_138_diff1</th>\n",
       "      <th>D_139_diff1</th>\n",
       "      <th>D_140_diff1</th>\n",
       "      <th>D_141_diff1</th>\n",
       "      <th>D_142_diff1</th>\n",
       "      <th>D_143_diff1</th>\n",
       "      <th>D_144_diff1</th>\n",
       "      <th>D_145_diff1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...</td>\n",
       "      <td>0.933824</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.868580</td>\n",
       "      <td>0.960384</td>\n",
       "      <td>0.934745</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.832050</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000fd6641609c6ece5454664794f0340ad84dddce9a2...</td>\n",
       "      <td>0.899820</td>\n",
       "      <td>0.022119</td>\n",
       "      <td>0.861109</td>\n",
       "      <td>0.929122</td>\n",
       "      <td>0.880519</td>\n",
       "      <td>7.153846</td>\n",
       "      <td>6.743468</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001b22f846c82c51f6e3958ccd81970162bae8b007e8...</td>\n",
       "      <td>0.878454</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.797670</td>\n",
       "      <td>0.904482</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006491</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000041bdba6ecadd89a52d11886e8eaaec9325906c9723...</td>\n",
       "      <td>0.598969</td>\n",
       "      <td>0.020107</td>\n",
       "      <td>0.567442</td>\n",
       "      <td>0.623392</td>\n",
       "      <td>0.621776</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>3.017046</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...</td>\n",
       "      <td>0.891679</td>\n",
       "      <td>0.042325</td>\n",
       "      <td>0.805045</td>\n",
       "      <td>0.940382</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean   P_2_std  \\\n",
       "0  0000099d6bd597052cdcda90ffabf56573fe9d7c79be5f...  0.933824  0.024194   \n",
       "1  00000fd6641609c6ece5454664794f0340ad84dddce9a2...  0.899820  0.022119   \n",
       "2  00001b22f846c82c51f6e3958ccd81970162bae8b007e8...  0.878454  0.028911   \n",
       "3  000041bdba6ecadd89a52d11886e8eaaec9325906c9723...  0.598969  0.020107   \n",
       "4  00007889e4fcd2614b6cbe7f8f3d2e5c728eca32d9eb8a...  0.891679  0.042325   \n",
       "\n",
       "    P_2_min   P_2_max  P_2_last  D_39_mean  D_39_std  D_39_min  D_39_max  ...  \\\n",
       "0  0.868580  0.960384  0.934745   0.230769  0.832050         0         3  ...   \n",
       "1  0.861109  0.929122  0.880519   7.153846  6.743468         0        19  ...   \n",
       "2  0.797670  0.904482  0.880875   0.000000  0.000000         0         0  ...   \n",
       "3  0.567442  0.623392  0.621776   1.538462  3.017046         0         9  ...   \n",
       "4  0.805045  0.940382  0.871900   0.000000  0.000000         0         0  ...   \n",
       "\n",
       "   D_136_diff1  D_137_diff1  D_138_diff1  D_139_diff1  D_140_diff1  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   D_141_diff1  D_142_diff1  D_143_diff1  D_144_diff1  D_145_diff1  \n",
       "0          0.0          NaN          0.0    -0.003376          0.0  \n",
       "1          0.0          NaN          0.0     0.000641          0.0  \n",
       "2          0.0          NaN          0.0    -0.006491          0.0  \n",
       "3          0.0          NaN          0.0     0.000741          0.0  \n",
       "4          0.0          NaN          0.0     0.000618          0.0  \n",
       "\n",
       "[5 rows x 1258 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target label file\n",
    "targets = pd.read_csv('C:\\\\Users\\\\16122\\\\AMEX Kaggle Competition\\\\train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(targets, how = 'left', on = 'customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del targets\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_cols = [col for col in list(train.columns) if col not in ['customer_ID','S_2','target']]\n",
    "for col in new_cols:\n",
    "    if train[col].dtype == 'float16' or train[col].dtype == 'float64':\n",
    "        train[col] = train[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_cols:\n",
    "    if train[col].dtype == 'int64':\n",
    "        train[col] = train[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('C:\\\\Users\\\\16122\\\\AMEX Kaggle Competition\\\\train_newnn_fe.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_parquet('C:\\\\Users\\\\16122\\\\AMEX Kaggle Competition\\\\test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['S_2']=pd.to_datetime(test['S_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_diff = get_difference(test, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process_and_feature_engineer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_mean_diff(test, last_mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_max_ratio(test, last_mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(test_diff, how = 'left', on = 'customer_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_diff\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new_cols = [col for col in list(test.columns) if col not in ['customer_ID','S_2']]\n",
    "for col in new_cols:\n",
    "    if test[col].dtype == 'float16' or test[col].dtype == 'float64':\n",
    "        test[col] = test[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_cols:\n",
    "    if test[col].dtype == 'int16' or test[col].dtype == 'int64':\n",
    "        test[col] = test[col].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_parquet('C:\\\\Users\\\\16122\\\\AMEX Kaggle Competition\\\\test_newnn_fe.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
